---
title: "Notes"
output:
  pdf_document: default
urlcolor: blue
date: "2024-05-15"
header-includes: 
  - \DeclareMathOperator*{\argmin}{arg\,min}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# devtools::install_github("mfasiolo/electBook")
library(electBook)
data(Irish)

summary(Irish$survey)
print("--------------------------------------")
print("--------------------------------------")
print("--------------------------------------")
summary(Irish$extra)
```

# Gaussian Process Regression

Gaussian process regression seems like a good fit for our noisy data, especially since we will have a distribution of possible `demand` points for each `dateTime`, corresponding to the uncertainty in our predictions.

## Theory

A gaussian process is a collection of random variables, which have a joint Gaussian distribution. A Gaussian process is completely specified by its mean function and covariance function. We build the following model:

Let $y_i = f(x_i) + \varepsilon_i$, where $f(x) \sim \text{GP}(0, k(x, x'))$ and $\varepsilon_i \sim N(0, \sigma^2)$. Then we can find the posterior distribution of $f(x_*)$ given $y$ as:

$$
f(x_*) | y \sim N(\mu(x_*), \sigma^2(x_*))
$$

where $\mu(x_*) = k(x_*, x)^T(K + \sigma^2I)^{-1}y$ and $\sigma^2(x_*) = k(x_*, x_*) - k(x_*, x)^T(K + \sigma^2I)^{-1}k(x_*, x)$. In pratice, to find the posterior distribution, we maximise the marginal log-likelihood.

## Implementation

```{r}
library(kernlab)
library(tidyverse)

# Data cleaning
# Sample a subset of households for plotting
house_sample <- sample(colnames(Irish$indCons), 2)

irish_demand_sample <- Irish$indCons[,house_sample] %>%
  bind_cols(Irish$extra) %>% # add time-related variables
  pivot_longer(cols = all_of(house_sample), names_to = "house_sample", values_to = "demand") %>%
  # Data cleaning
  select(-time, -holy) %>% 
  # Feature engineering
  mutate(
    hour = hour(dateTime),
    month = month(dateTime),
    weekend = ifelse(dow %in% c("Sat", "Sun"), 1, 0)
  ) %>% 
  mutate(temp_sq = temp^2) %>%  # quadratic term for temperature
  # One-hot encode the day of the week
  bind_cols(model.matrix(~ dow - 1, data = .)) %>% 
  select(-dow)


irish_demand_train <- irish_demand_sample %>% 
  filter(dateTime < "2010-12-01")

irish_demand_test <- irish_demand_sample %>%
  filter(dateTime >= "2010-12-01")

summary(irish_demand_test)
print(house_sample)
#Plot demand over a week for two sample households
irish_demand_sample %>%
  filter(dateTime >= "2010-12-01" & dateTime < "2010-12-08") %>%
  ggplot(aes(x = dateTime, y = demand)) +
  geom_line() +
  facet_wrap(~house_sample, scales = "free_y") +
  labs(title = "Electricity demand over a week for two sample households",
       x = "Date", y = "Electricity demand (kWh)")

irish_demand_sample %>%
  filter(dateTime >= "2010-12-01" & dateTime < "2010-12-08") %>%
  ggplot() +
  geom_line(aes(x = dateTime, y = demand), color = "#ffa908") +
  geom_line(aes(x = dateTime, y = demand), color = "#00b7ff") +
  labs(title = "Electricity demand over time for a sample household",
       x = "Date", y = "Electricity demand (kWh)")
```

```{r}

neg_marginal <- function(params){
  lambda <- params[1]
  psi <- params[2]
  #Compute K_n and K+lambdaI
  K <- kernelMatrix(rbfdot(sigma = psi), x)
  L <- K + lambda*diag(n)
  if (det(L) == 0){
    return(Inf)
  }
  #Compute alpha
  y <- as.matrix(y)
  alpha = solve(L,y)
  #Compute neg log marginal likelihood
  neg_marginal_val <- 0.5*(t(y)%*%alpha + sum(log(diag(L))))

  return(neg_marginal_val)
}
```

