---
title: "Notes"
output:
  pdf_document: default
urlcolor: blue
date: "2024-05-15"
header-includes: 
  - \DeclareMathOperator*{\argmin}{arg\,min}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Import the data

We are using a dataset of Irish household electricity demand available from the `electBook` package. We have three datasets:

- `indCons`: 16799 x 2672 matrix of individual household electricity consumption. Each column corresponds to a household and each row to a time point. Demand is observed every half hour, so there are 48 observations per day per household.
- `survey`: 2672 row dataframe of household survey data. This dataset contains household level data on variables such as social class, renting vs. owning, appliances, etc.
- `extra`: 16799 row dataframe of time-related variables. This dataset contains the date-time of each demand observation, time of year, day of week, time of day, whether the day was a holiday, and external temperature.

```{r}
# Extract individual dataframes
library(electBook)
data(Irish)
indCons <- Irish[["indCons"]]
survey <- Irish[["survey"]]
extra <- Irish[["extra"]]
```

# Exploratory data analysis

## Temperature

Let's check any relationship between temperature and demand.

```{r}
library(tidyverse)

# Data cleaning
# Sample a subset of households for plotting
house_sample <- sample(colnames(Irish$indCons), 20)
irish_demand_sample <- Irish$indCons[,house_sample] %>%
  as.data.frame() %>%
  # Row numbers to column
  mutate(time = 1:nrow(.)) %>%
  pivot_longer(-time, names_to = "household", values_to = "demand") %>% 
  left_join(Irish$extra %>% select(time, temp), by = "time")

# Plot demand vs. temperature
ggplot(irish_demand_sample, aes(x = temp, y = demand)) +
  geom_point() +
  theme_bw()

```

Might be a quadratic relationship? (very noisy)

## Social class

Do households from different social classes happen to have different demand patterns? [This Wikipedia page](https://en.wikipedia.org/wiki/NRS_social_grade) summarises the social classes and notes that F is an additional class for farmers.

```{r}
# Get agg as in basic_lin_reg.R
agg <- rowSums(Irish[["indCons"]])

# Separate aggregates by social class
agg_ab <- rowSums(Irish[["indCons"]][, Irish[["survey"]]$SOCIALCLASS == "AB"])
agg_c1 <- rowSums(Irish[["indCons"]][, Irish[["survey"]]$SOCIALCLASS == "C1"])
agg_c2 <- rowSums(Irish[["indCons"]][, Irish[["survey"]]$SOCIALCLASS == "C2"])
agg_de <- rowSums(Irish[["indCons"]][, Irish[["survey"]]$SOCIALCLASS == "DE"])
agg_f <- rowSums(Irish[["indCons"]][, Irish[["survey"]]$SOCIALCLASS == "F"])

# Plot demand by social class
# All-time
# ggplot(data = extra, aes(x = time)) +
#   # geom_line(aes(y = agg, color = "Total")) +
#   geom_line(aes(y = agg_ab, color = "AB"), alpha = 0.5) +
#   geom_line(aes(y = agg_c1, color = "C1"), alpha = 0.5) +
#   geom_line(aes(y = agg_c2, color = "C2"), alpha = 0.5) +
#   geom_line(aes(y = agg_de, color = "DE"), alpha = 0.5) +
#   geom_line(aes(y = agg_f, color = "F"), alpha = 0.5) +
#   theme_bw()

# 1 month
# Plot demand by social class
ggplot(data = Irish[["extra"]][1:(48*30),], aes(x = time)) +
  geom_line(aes(y = agg_ab[1:(48*30)], color = "AB"), alpha = 0.5) +
  geom_line(aes(y = agg_c1[1:(48*30)], color = "C1"), alpha = 0.5) +
  geom_line(aes(y = agg_c2[1:(48*30)], color = "C2"), alpha = 0.5) +
  geom_line(aes(y = agg_de[1:(48*30)], color = "DE"), alpha = 0.5) +
  geom_line(aes(y = agg_f[1:(48*30)], color = "F"), alpha = 0.5) +
  theme_bw()
```

Class F certainly has a much different pattern than the other classes, and there are some other distinctive class differences.

## Seasonal patterns

Let's look at the seasonal patterns in the data.

```{r}
# Plot demand for one day
ggplot() +
  geom_line(aes(x = 49:(48*2), y = agg[49:(48*2)])) +
  theme_bw()

# Plot demand for one week
ggplot() +
  geom_line(aes(x = 1:(48*7), y = agg[1:(48*7)])) +
  theme_bw()
ggplot() +
  geom_line(aes(x = (48*7+1):(48*7*2), y = agg[(48*7+1):(48*7*2)])) +
  theme_bw()

# Plot demand for one month
ggplot() +
  geom_line(aes(x = 1:(48*30), y = agg[1:(48*30)])) +
  theme_bw()
ggplot() +
  geom_line(aes(x = (48*30 + 1):(48*30*2), y = agg[(48*30 + 1):(48*30*2)])) +
  theme_bw()

# Plot all demand
ggplot() +
  geom_line(aes(x = 1:length(agg), y = agg)) +
  theme_bw()
```

# Ridge regression by social class

## Half hour

```{r}
library(Rcpp)
sourceCpp(code = '
          #include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
NumericMatrix generate_fourier_terms(NumericVector time_counter, int K, double period) {
  int n = time_counter.size();
  NumericMatrix terms(n, 2 * K);
  
  for (int i = 0; i < n; ++i) {
    for (int k = 1; k <= K; ++k) {
      terms(i, 2 * (k - 1)) = sin(2 * M_PI * k * time_counter[i] / period);
      terms(i, 2 * (k - 1) + 1) = cos(2 * M_PI * k * time_counter[i] / period);
    }
  }
  
  return terms;
}
          ')
```


```{r}
# Load half hour data
# df_halfhr <- readRDS("../data/df_halfhr.RData")
df_halfhr_scaled <- readRDS("../data/df_halfhr_scaled.RData")

# Add Fourier terms
fourier_halfhr_daily <- generate_fourier_terms(df_halfhr_scaled$counter, K = 5, period = 48)
colnames(fourier_halfhr_daily) <- paste0(rep(c("daily_sin_","daily_cos_"),
                                             ncol(fourier_halfhr_daily) / 2),
                                         rep(seq_len(ncol(fourier_halfhr_daily) / 2), each = 2))
fourier_halfhr_yearly <- generate_fourier_terms(df_halfhr_scaled$counter, K = 5, period = 48 * 365)
colnames(fourier_halfhr_yearly) <- paste0(rep(c("yearly_sin_","yearly_cos_"),
                                             ncol(fourier_halfhr_yearly) / 2),
                                         rep(seq_len(ncol(fourier_halfhr_yearly) / 2), each = 2))
halfhr_fourier <- cbind(df_halfhr_scaled, fourier_halfhr_daily, fourier_halfhr_yearly) %>% 
  select(-counter)

# Scale fourier terms
halfhr_fourier_scaled <- halfhr_fourier %>% 
  mutate(across(starts_with(c("daily", "yearly")), ~ as.vector(scale(.))))

# Split the data into training and test sets
# 90% training set
n_train <- round(0.9*nrow(halfhr_fourier_scaled))
halfhr_features_train <- halfhr_fourier_scaled[1:n_train,]
halfhr_features_test <- halfhr_fourier_scaled[-(1:n_train),]
```

Fit the models:

```{r}
# Fit the ridge regression model
library(glmnet)
library(ggplot2)
de_halfhr_ridge <- cv.glmnet(as.matrix(halfhr_features_train[,7:ncol(halfhr_features_train)]),
                                halfhr_features_train$DE,
                                family = "gaussian",
                                alpha = 0, # Ridge regression
                                type.measure = "mse",
                                nfolds = 10)

# Investigate coefficients
# glmnet_beta <- coef(de_halfhr_ridge, s = de_halfhr_ridge$lambda.min)
# raw_pred <- halfhr_X_test %*% glmnet_beta@x

# Predict on the test set
de_halfhr_pred <- predict(de_halfhr_ridge,
                          newx = as.matrix(halfhr_features_test[,7:ncol(halfhr_features_test)])
                          )
# Calculate MSE
de_halfhr_mse <- mean((de_halfhr_pred - halfhr_features_test$DE)^2) # 0.02322218
# Plot the predictions on the test set
ggplot(halfhr_features_test, aes(x = dateTime, y = DE)) +
  geom_line() +
  geom_line(aes(y = de_halfhr_pred), color = "red")
```

Test out the Rcpp ridge regression functions:

```{r}
library(Rcpp)
library(RcppArmadillo)
library(RcppParallel)
Rcpp::sourceCpp(code='
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::depends(RcppParallel)]]
// [[Rcpp::plugins(openmp)]]

#include <RcppArmadillo.h>
#include <RcppParallel.h>
using namespace Rcpp;
using namespace RcppParallel;

// Function to perform ridge regression and compute CV error
// [[Rcpp::export]]
List performRidgeRegression(const arma::mat& X, const arma::vec& y, double lambda) {
  int n = X.n_rows;
  int k = X.n_cols + 1; // adding one column for the intercept
  
  // Add a column of ones to X for the intercept
  arma::mat X_with_intercept = arma::join_horiz(arma::ones<arma::vec>(n), X);
  
  // Compute XtX and XtY
  arma::mat XtX = arma::trans(X_with_intercept) * X_with_intercept;
  arma::mat ridgePenalty = lambda * arma::eye<arma::mat>(k, k);
  ridgePenalty(0, 0) = 0; // Do not penalize the intercept term
  arma::mat XtX_ridge = XtX + ridgePenalty;
  
  arma::colvec coef = arma::solve(XtX_ridge, arma::trans(X_with_intercept) * y);
  arma::colvec resid = y - X_with_intercept * coef;
  double sig2 = arma::as_scalar(arma::trans(resid) * resid / n); 
  
  return List::create(_["error"] = sig2, _["coefficients"] = coef);
}
')
```

Try it on our data:

```{r}
halfhr_ridge_test <- performRidgeRegression(
  X = as.matrix(halfhr_features_train[,7:ncol(halfhr_features_train)]),
  y = halfhr_features_train$DE,
  lambda = de_halfhr_ridge$lambda.1se * 15076 # Scale lambda by number of rows in training data
)

halfhr_X_test <- cbind(1, as.matrix(halfhr_features_test[, 7:ncol(halfhr_features_test)]))
halfhr_ridge_predict <- halfhr_X_test %*% halfhr_ridge_test$coefficients

# Plot the predictions on the test set
ggplot(halfhr_features_test, aes(x = dateTime, y = DE)) +
  geom_line() +
  geom_line(aes(y = halfhr_ridge_predict), color = "red")
```

Same prediction yay!


Now test the parallel version:

```{r}
Rcpp::sourceCpp(code='
// [[Rcpp::depends(RcppArmadillo)]]
// [[Rcpp::depends(RcppParallel)]]
// [[Rcpp::plugins(openmp)]]

#include <RcppArmadillo.h>
#include <RcppParallel.h>
using namespace Rcpp;
using namespace RcppParallel;

// Function to perform ridge regression and compute CV error
// [[Rcpp::export]]
List performRidgeRegression(const arma::mat& X, const arma::vec& y, double lambda) {
  int n = X.n_rows;
  int k = X.n_cols + 1; // adding one column for the intercept
  
  // Add a column of ones to X for the intercept
  arma::mat X_with_intercept = arma::join_horiz(arma::ones<arma::vec>(n), X);
  
  // Compute XtX and XtY
  arma::mat XtX = arma::trans(X_with_intercept) * X_with_intercept;
  arma::mat ridgePenalty = lambda * arma::eye<arma::mat>(k, k);
  ridgePenalty(0, 0) = 0; // Do not penalize the intercept term
  arma::mat XtX_ridge = XtX + ridgePenalty;
  
  arma::colvec coef = arma::solve(XtX_ridge, arma::trans(X_with_intercept) * y);
  arma::colvec resid = y - X_with_intercept * coef;
  double sig2 = arma::as_scalar(arma::trans(resid) * resid / n); 
  
  return List::create(_["error"] = sig2, _["coefficients"] = coef);
}
')
```


```{r}
lambda_values <- seq(0.01, 100, length.out = 100)
cv_results <- parallelRidgeCV(X = as.matrix(halfhr_features_train[,7:ncol(halfhr_features_train)]),
                             y = halfhr_features_train$DE,
                             lambda_values = lambda_values)

# Identify the optimal lambda
optimal_lambda <- lambda_values[which.min(cv_errors)]
print(paste("Optimal Lambda:", optimal_lambda))
```


# Ridge regression on total demand

## Clean data and fit model

We can also try ridge regression on the total demand across all households.

```{r}
total_demand <- data.frame(demand = agg) %>% 
  bind_cols(Irish[["extra"]]) %>% # add time-related variables
  # Data cleaning
  select(-time, -holy) %>% 
  # Feature engineering
  mutate(
    hour = hour(dateTime),
    month = month(dateTime),
    weekend = ifelse(dow %in% c("Sat", "Sun"), 1, 0)
  ) %>% 
  mutate(temp_sq = temp^2) %>%  # quadratic term for temperature
  # One-hot encode the day of the week
  bind_cols(model.matrix(~ dow - 1, data = .)) %>% 
  select(-dow)

# Add Fourier terms
fourier_agg_daily <- fourier(ts(total_demand$demand, frequency = 48), K = 5)
fourier_agg_weekly <- fourier(ts(total_demand$demand, frequency = 48 * 7), K = 5)

total_demand_fourier <- cbind(total_demand, fourier_agg_daily, fourier_agg_weekly)

# Scale numeric features
total_demand_scaled <- total_demand_fourier %>% 
  mutate(across(where(is.numeric), scale))

# Split the data into training and test sets
total_demand_train_scaled <- total_demand_scaled %>% 
  filter(dateTime < "2010-12-01") # Training set: all data before December 2010
# Test on the last month of the dataset
total_demand_test_scaled <- total_demand_scaled %>% 
  filter(dateTime >= "2010-12-01")

# Fit the ridge regression model
total_demand_ridge_scaled <- cv.glmnet(as.matrix(total_demand_train_scaled %>%
                                                   select(-demand, -dateTime)),
                                total_demand_train_scaled$demand,
                                family = "gaussian",
                                alpha = 0, # Ridge regression
                                type.measure = "mse",
                                nfolds = 10)

# Predict on the test set
total_demand_pred_scaled <- predict(total_demand_ridge_scaled, newx = as.matrix(total_demand_test_scaled %>% select(-demand, -dateTime)))
# Calculate MSE
total_demand_mse_scaled <- mean((total_demand_pred_scaled - total_demand_test_scaled$demand)^2)
print(paste("Ridge regression test error:", total_demand_mse_scaled))
# Plot the predictions on the test set
ggplot(total_demand_test_scaled, aes(x = dateTime, y = demand)) +
  geom_line() +
  geom_line(aes(y = total_demand_pred_scaled), color = "red")

# Plot the predictions on the last month of the training set
total_demand_train_pred <- predict(total_demand_ridge_scaled, newx = as.matrix(total_demand_train_scaled %>% filter(dateTime >= "2010-11-01") %>% select(-demand, -dateTime)))
ggplot(total_demand_train_scaled %>% filter(dateTime >= "2010-11-01"), aes(x = dateTime, y = demand)) +
  geom_line() +
  geom_line(aes(y = total_demand_train_pred), color = "red")
# Same peak problems on the training set as on the test set
```

The prediction is much better on the aggregate demand, although the predictions still never get to the high peaks in demand.

## Seasonal patterns

We have a regular fluctuation at the daily level:

```{r}
# Plot demand over day
ggplot(total_demand, aes(x = hour, y = demand)) +
  geom_point() +
  geom_smooth() +
  theme_bw()
```

There is a dip around 3:00 am, followed by a small peak around 9:00 am and a larger peak around 6:00-7:00 pm.

Let's look at the weekly level:

```{r}
# Plot demand over week
total_demand %>% 
  mutate(day_of_week = wday(dateTime)) %>% 
  ggplot(aes(x = day_of_week, y = demand, group = day_of_week)) +
  geom_boxplot() +
  theme_bw()
```

There may be some weekly fluctuation, but it isn't very clear.

Let's try monthly:

```{r}
# Plot demand over month
total_demand %>% 
  mutate(day_of_month = day(dateTime)) %>% 
  ggplot(aes(x = day_of_month, y = demand, group = day_of_month)) +
  geom_boxplot() +
  theme_bw()
```

Again, it's hard to see any major pattern.

Let's check annually:

```{r}
ggplot(total_demand, aes(x = month, y = demand)) +
  geom_point() +
  geom_smooth() +
  theme_bw()
```

It looks like we definitely have a dip in the summer months.

## Coefficients

Let's see which terms are most important:

```{r}
# Extract coefficients
total_demand_coefs <- coef(total_demand_ridge_scaled, s = "lambda.min") %>% as.matrix()

# Standardize the coefficients (multiply by the standard deviation of the corresponding feature)
standard_deviations_total <- apply(as.matrix(total_demand_train_scaled %>% select(-demand, -dateTime)), 2, sd)
standardized_coefficients_total <- total_demand_coefs[-1, ] * standard_deviations_total # Exclude the intercept

# Plot the coefficients
total_coefficients_df <- data.frame(
  feature = names(standardized_coefficients_total),
  coefficient = as.numeric(standardized_coefficients_total)
)
ggplot(total_coefficients_df, aes(x = reorder(feature, coefficient), y = coefficient)) +
  geom_col() +
  coord_flip() +
  theme_bw()
```

The variables `tod` and `hour` have relatively large magnitude coefficients, as do `temp` and `temp_sq`. The daily Fourier terms also have relatively large coefficients, while the weekly ones do not.

## Investigate peaks

Where are these peaks?

```{r}
# Peaks occur when total demand is above 3000
ggplot(total_demand %>% filter(demand > 3000), aes(x = hour, y = demand)) +
  geom_point() +
  theme_bw()
```

Most of the peaks are around 5-6 pm.

