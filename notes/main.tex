% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={SC-2 Electric Boogalo},
  pdfauthor={Kieran Morris, Cecina Babich Morrow and Sherman Kjo},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\title{SC-2 Electric Boogalo}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Regression on the Irish datset agregated by class}
\author{Kieran Morris, Cecina Babich Morrow and Sherman Kjo}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{cleaning-the-data}{%
\section{Cleaning the Data}\label{cleaning-the-data}}

\hypertarget{data-overview}{%
\subsection{Data overview}\label{data-overview}}

We are analyzing a set of Irish household electricity demand available
from the \texttt{electBook} package. We have three datasets:

\begin{itemize}
\tightlist
\item
  \texttt{indCons}: 16799 x 2672 matrix of individual household
  electricity consumption. Each column corresponds to a household and
  each row to a time point. Demand is observed every half hour, so there
  are 48 observations per day per household.
\item
  \texttt{survey}: 2672 row dataframe of household survey data. This
  dataset contains household level data on variables such as social
  class, renting vs.~owning, appliances, etc.
\item
  \texttt{extra}: 16799 row dataframe of time-related variables. This
  dataset contains the date-time of each demand observation, time of
  year, day of week, time of day, whether the day was a holiday, and
  external temperature.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract individual dataframes}
\KeywordTok{library}\NormalTok{(electBook)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{data}\NormalTok{(Irish)}
\NormalTok{indCons \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"indCons"}\NormalTok{]]}
\NormalTok{survey \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"survey"}\NormalTok{]]}
\NormalTok{extra \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"extra"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\hypertarget{social-class}{%
\subsection{Social class}\label{social-class}}

We wanted to investigate demand patterns across different social
classes. The dataset includes 5 social classes, defined by the
occupation of the head of household:

\begin{itemize}
\tightlist
\item
  AB: managerial roles, administrative or professional
\item
  C1: supervisory, clerical, junior managerial
\item
  C2: skilled manual workers
\item
  DE: semi-skilled and unskilled manual workers, state pensioners,
  casual workers
\item
  F: farmers
\end{itemize}

** Insert plot of demand patterns for different classes **

We modeled the average demand for each social class separately.

\hypertarget{loading-and-structure}{%
\subsection{Loading and Structure}\label{loading-and-structure}}

We cleaned the data using the code available in
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/blob/main/data_cleaning.R}{\texttt{data\_cleaning.R}},
which writes out three dataframes: \texttt{df\_halfhr}, \texttt{df\_hr},
and \texttt{df\_day}. These dataframes contain the half-hourly, hourly,
and daily average demand data for each social class, as well as
temperature (also aggregated to the relevant time scale), time of year
(the time of year with 1st January represented as 0 and 31st December
represented as 1), and day of the week. These dataframes are written to
the
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/tree/main/data}{\texttt{data}
folder}.

\hypertarget{feature-engineering}{%
\subsection{Feature engineering}\label{feature-engineering}}

Based on exploratory data analysis, we created some features from the
dataset to model demand. Feature engineering (with the exception of the
addition of the Fourier terms) was performed in the
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/blob/main/feature_engineering.R}{\texttt{feature\_engineering.R}
script}, and the resulting dataframes \texttt{df\_halfhr\_scaled},
\texttt{df\_hr\_scaled}, and \texttt{df\_day\_scaled} were saved to the
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/tree/main/data}{\texttt{data}
folder}.

\hypertarget{time-related-features}{%
\subsubsection{Time-related features}\label{time-related-features}}

We extracted the hour of the day and the month from the date-time
variable. We also included a quadratic term for temperature to capture
the non-linear relationship between temperature and demand. We also used
one-hot encoding to include the day of the week in our models.

\hypertarget{temperature}{%
\subsubsection{Temperature}\label{temperature}}

We can visualize the relationship between temperature and the aggregate
demand over time across all households:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{agg \textless{}{-}}\StringTok{ }\KeywordTok{colMeans}\NormalTok{(indCons)}

\NormalTok{temp\_demand \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{demand =}\NormalTok{ agg) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{bind\_cols}\NormalTok{(Irish[[}\StringTok{"extra"}\NormalTok{]])}

\KeywordTok{ggplot}\NormalTok{(temp\_demand, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dateTime, }\DataTypeTok{y =}\NormalTok{ demand, }\DataTypeTok{color =}\NormalTok{ temp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\NormalTok{viridis}\OperatorTok{::}\KeywordTok{scale\_color\_viridis}\NormalTok{(}\DataTypeTok{option =} \StringTok{"magma"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Total Demand"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"Temperature"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We can see that during the warmer summer months, demand dips, although
the pattern is messy. We included linear and quadratic terms for
temperature in our models.

\hypertarget{fourier-terms}{%
\subsubsection{Fourier terms}\label{fourier-terms}}

We used Fourier terms to capture the patterns of seasonality in the
data. Fourier terms are a set of sine and cosine functions with
different frequencies that can be used to model periodic patterns. For a
given period \(P\), the Fourier terms are defined as follows:
\[\text{sin}_k(t) = \sin\left(\frac{2\pi kt}{P}\right), \quad \text{cos}_k(t) = \cos\left(\frac{2\pi kt}{P}\right)\]
where \(k\) is the frequency and \(t\) is the time. Then a partial
Fourier sum can be written as
\[ y(t) = \beta_0 + \sum_{k=1}^{K} \left( \beta_{1k} \sin\left(\frac{2\pi kt}{P}\right) + \beta_{2k} \cos\left(\frac{2\pi kt}{P}\right) \right) \]
where \(K\) is the maximum order of Fourier terms to use.

We used Fourier terms to model the daily and annual seasonality in the
data. Since our dataset is missing data for some days, we needed to
adjust the \(t\) used to calculate the Fourier terms to account for
these gaps. In the
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/blob/main/feature_engineering.R}{\texttt{feature\_engineering.R}
script}, we added the variable \texttt{counter} to all dataframes. This
variable increments by one for each time step (half hour, hour, or day)
in the dataframe, reflecting the fact that some days are missing. These
\texttt{counter} variables were then used later on to generate Fourier
terms for our models. We wrote an \texttt{Rcpp} function in our package
called \texttt{generate\_fourier\_terms}, which creates a matrix of
Fourier terms given a time counter variable representing \(t\), the
maximum order of the Fourier terms \(K\), and the number of time
increments in a period \(P\).

\textbf{Insert example of \texttt{generate\_fourier\_terms} function}

\hypertarget{scaling}{%
\subsection{Scaling}\label{scaling}}

We centered and scaled all variables used in the models.

\hypertarget{training-and-testing}{%
\subsection{Training and testing}\label{training-and-testing}}

Because this is time series data, we needed to make sure the training
and testing data were both contiguous. We trained the models on the
first 90\% of the rows and tested on the final 10\%.

\hypertarget{ridge-regression}{%
\section{Ridge Regression}\label{ridge-regression}}

\hypertarget{theory}{%
\subsection{Theory}\label{theory}}

Ridge regression is a method for penalized regression. Consider the
model \[Y_i^0 = \alpha + \beta x_i^0 + \epsilon_i, \quad  i = 1,..., n\]
where \(\beta \in \mathbb{R}^p\), \(\alpha \in \mathbb{R}\), and for all
\(i, l \in \{1, ..., n\}\), \(\mathbb{E}[\epsilon_i] = 0\) and
\(\mathbb{E}[\epsilon_i \epsilon_l] = \sigma^2 \delta_{il}\) for some
\(\sigma^2 > 0\). Then the ridge regression estimator is defined as the
minimizer of the following objective function:
\[(\hat{\alpha}_\lambda, \hat{\beta}_\lambda) = \mathrm{argmin}_{\alpha \in \mathbb{R}, \beta \in \mathbb{R}^p} \lVert y^0 - \alpha - \boldsymbol{X}^0 \beta \rVert^2_2 + \lambda \lVert \beta \rVert^2_2\]
where \(\lambda > 0\) is a tuning parameter and
\(\lVert \cdot \rVert_2\) denotes the Euclidean norm. Ridge regression
is thus imposing a penalty on the size of \(\beta\), with the strength
of that penalty determined by the choice of \(\lambda\). The
coefficients will be shrunk towards zero, but will not be set to zero
(as opposed to in lasso regression).

\hypertarget{model}{%
\subsection{Model}\label{model}}

We performed ridge regression using the model detailed above, with the
following input variables:

\begin{itemize}
\tightlist
\item
  Temperature and squared temperature
\item
  Time of year
\item
  Hour
\item
  Month
\item
  One-hot encoded variables for each day of the week
\item
  Daily Fourier terms
  \(\text{sin}_k(t) = \sin\left(\frac{2\pi kt}{P}\right), \quad \text{cos}_k(t) = \cos\left(\frac{2\pi kt}{P}\right)\)
  for \(k \in \{1,...,K\}\)
\item
  Annual Fourier terms likewise
\end{itemize}

We had two hyperparameters to tune: the standard ridge regression
parameter \(\lambda\) and the maximum order of the Fourier terms
included \(K\). For sake of simplicity, we elected to use the same \(K\)
value for both the daily and the annual terms.

\hypertarget{implementation}{%
\subsection{Implementation}\label{implementation}}

We implemented ridge regression using \texttt{RcppArmadillo}. To select
\(\lambda\), we used \(k\)-fold cross-validation, also implemented in
\texttt{RcppArmadillo} using \texttt{RcppParallel} to parallelise the
cross-validation process. These functions can be found in our package in
the
\href{https://github.com/Shermjj/SC-2-Electric-Boogalo/blob/main/ElecForecast/src/ridge_regression.h}{\texttt{ridge\_regression.h}
file}.

\hypertarget{gaussian-process-regression}{%
\section{Gaussian Process
Regression}\label{gaussian-process-regression}}

\hypertarget{theory-1}{%
\subsection{Theory}\label{theory-1}}

A gaussian process \(W = (W(x))_{x \in \mathcal{X}}\) is a collection of
random variables, which have a joint Gaussian distribution. One useful
fact is that a Gaussian process is completely specified by its mean
(\(\mu:\mathcal{X} \rightarrow \mathbb{R}\)) and covariance
(\(k:\mathcal{X}^2 \rightarrow \mathbb{R}\)) functions - meaning the
objective of GPR is to obtain the mean and covariance. This allows us to
express any finite collection of \(W\) as follows:

\[
(W(x_1), W(x_2), ..., W(x_n)) \sim N((\mu(x_1),...\mu(x_n)), (k(x_i,x_j))_{ij})
\]

We build the following model:

Let \(y_i = f(x_i) + \varepsilon_i\), where
\(\varepsilon_i \sim N(0, \sigma^2)\) and we let \(f\) be a gaussian
process. It can be shown that

\[
f \mid y^0 \sim \text{GP}(f_n,k_n)
\]

where \[f_n(x) = k^n(x)^T(K + \sigma^2I_n)^{-1}y^0,\]
\[k(x,x*) = k(x, x^*) - k^n(x)^T (K + \sigma^2 I_n)^{-1} k^n(x^*)\] and

\[
K = (k(x_i^0,x_j^0))_{ij}
\]

\[
k^n(x) = (k(x_1^0,x),k(x_n^0,x)).
\] Although if it looks scary just remember a computer can do it! This
gives us a way to then model

\[Y^0 \sim \text{N}(0,K _ \lambda I_n),\]

to simulate our results.

In practice, to find the posterior distribution, we maximise the
marginal log-likelihood.

\hypertarget{tuning-hyperparameters}{%
\subsection{Tuning hyperparameters}\label{tuning-hyperparameters}}

For our needs we will use a radial basis function kernel, which has a
single hyperparemter \(l\), often called the bandwidth.

\[
k(x, x') = \exp\left(-\frac{\lVert x - x' \rVert^2}{2l}\right)
\]

We also have the hyperparameter \(\sigma\) which is the standard
deviation of our noise. In order to find the ideal hyperparameters we
will attempt to maximize the marginal log likelihood. The marginal log
likelihood is given by:

\[
\log p(y^0 \mid x^0, l,\sigma^2) = -\frac{1}{2} y^0 (K + \sigma^2 I_n)^{-1} y^0 - \frac{1}{2} \log \lvert K + \sigma^2 I_n \rvert 
\]

where we remove a constant which is irrelevant to the optimisation.
Since this is computationaly intense, we outsource the optimisation to
C++, and integrate it via RcppArmadillo. Below is the C++ code we used,
which can also be found \texttt{gauss\_process\_reg.cpp}:

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}RcppArmadillo.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}optim.hpp\textgreater{}}

\CommentTok{// [[Rcpp::depends(RcppArmadillo)]]}

\CommentTok{// Define the RBF kernel}
\NormalTok{arma::mat rbf\_kernel(}\AttributeTok{const}\NormalTok{ arma::mat\& X, }\DataTypeTok{double}\NormalTok{ l, }\DataTypeTok{double}\NormalTok{ sigma) \{}
\NormalTok{    arma::mat K = arma::zeros(X.n\_rows, X.n\_rows);}
    \ControlFlowTok{for}\NormalTok{ (}\DataTypeTok{unsigned}\NormalTok{ i = }\DecValTok{0}\NormalTok{; i \textless{} X.n\_rows; ++i) \{}
        \ControlFlowTok{for}\NormalTok{ (}\DataTypeTok{unsigned}\NormalTok{ j = }\DecValTok{0}\NormalTok{; j \textless{} X.n\_rows; ++j) \{}
            \DataTypeTok{double}\NormalTok{ dist = arma::norm(X.row(i) {-} X.row(j), }\DecValTok{2}\NormalTok{);}
\NormalTok{            K(i, j) = }\BuiltInTok{std::}\NormalTok{pow(sigma, }\DecValTok{2}\NormalTok{) * }\BuiltInTok{std::}\NormalTok{exp({-}}\BuiltInTok{std::}\NormalTok{pow(dist, }\DecValTok{2}\NormalTok{) / (}\DecValTok{2}\NormalTok{ * }\BuiltInTok{std::}\NormalTok{pow(l, }\DecValTok{2}\NormalTok{)));}
\NormalTok{        \}}
\NormalTok{    \}}
    \ControlFlowTok{return}\NormalTok{ K;}
\NormalTok{\}}

\CommentTok{// Define the negative log marginal likelihood}
\DataTypeTok{double}\NormalTok{ neg\_log\_marginal\_likelihood(}\AttributeTok{const}\NormalTok{ arma::vec\& theta, arma::vec* grad\_out, }\DataTypeTok{void}\NormalTok{* opt\_data) \{}
    \CommentTok{// Extract data and parameters}
\NormalTok{    arma::mat X = *}\KeywordTok{static\_cast}\NormalTok{\textless{}arma::mat*\textgreater{}(opt\_data);}
\NormalTok{    arma::vec y = *}\KeywordTok{static\_cast}\NormalTok{\textless{}arma::vec*\textgreater{}(opt\_data);}
    \DataTypeTok{double}\NormalTok{ l = theta(}\DecValTok{0}\NormalTok{);}
    \DataTypeTok{double}\NormalTok{ sigma = theta(}\DecValTok{1}\NormalTok{);}

    \CommentTok{// Calculate the kernel matrix}
\NormalTok{    arma::mat K = rbf\_kernel(X, l, sigma);}

    \CommentTok{// Calculate the log marginal likelihood}
    
    \DataTypeTok{double}\NormalTok{ log\_likelihood = {-}}\FloatTok{0.5}\NormalTok{ * arma::as\_scalar(y.t() * arma::solve(K, y)) {-} }\FloatTok{0.5}\NormalTok{ * arma::log\_det(K + l ) {-} }\FloatTok{0.5}\NormalTok{ * X.n\_rows * }\BuiltInTok{std::}\NormalTok{log(}\DecValTok{2}\NormalTok{ * M\_PI);}

    \CommentTok{// Return the negative log marginal likelihood}
    \ControlFlowTok{return}\NormalTok{ {-}log\_likelihood;}
\NormalTok{\}}

\CommentTok{// [[Rcpp::export]]}
\NormalTok{arma::vec optimise\_gaussian\_process(arma::mat X, arma::vec y) \{}
    \CommentTok{// Initial guess for the parameters}
\NormalTok{    arma::vec theta = arma::ones(}\DecValTok{2}\NormalTok{);}

    \CommentTok{// Optimise the negative log marginal likelihood}
    \DataTypeTok{bool}\NormalTok{ success = optim::de(theta, neg\_log\_marginal\_likelihood, \&X);}

    \CommentTok{// Return the optimised parameters}
    \ControlFlowTok{return}\NormalTok{ theta;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We parallize over the grid of initial choices to speed up the
optimisation. As we going to be performing this on different sized
datasets (half hourly, hourly and daily) it is unwise to perform
parallisation over those. Instead we created an wrapper function in
\texttt{R} which can take in an arbitrary dataset. We display it below
but it can be found in \texttt{gauss\_process\_reg.R}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find\_optimal\_params \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, y) \{}
  \CommentTok{\# Source the C++ file}
  \KeywordTok{sourceCpp}\NormalTok{(}\StringTok{"gauss\_process\_reg.cpp"}\NormalTok{)}
  
  \CommentTok{\# Call the C++ function}
\NormalTok{  theta \textless{}{-}}\StringTok{ }\KeywordTok{optimise\_gaussian\_process}\NormalTok{(X, y)}
  
  \CommentTok{\# Return the optimal parameters}
  \KeywordTok{return}\NormalTok{(theta)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{implementation-1}{%
\subsection{Implementation}\label{implementation-1}}

For the gaussian process regression, we will use the
\texttt{kernlab::gausspr} function, which can perform multivariate
gaussian process regression, allowing us to add our additional features
as covariates. Since we have our ideal hyperparameters \(l\) and
\(\sigma\) for each dataset, we can now fit the gaussian process
regression model fairly easily. Source code for the following can be
found in \texttt{gauss\_process\_reg.R}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gaussian\_process\_reg \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(data,}
                                 \DataTypeTok{class =} \StringTok{"DE"}\NormalTok{,}
                                 \DataTypeTok{kernel =} \StringTok{"rbfdot"}\NormalTok{,}
                                 \DataTypeTok{plot =} \OtherTok{FALSE}\NormalTok{,}
                                 \DataTypeTok{sigma =} \DecValTok{100}\NormalTok{) \{}

  \CommentTok{\#Training and test set, first 90\% of data is training, last 10\% is test}
\NormalTok{  train\_index \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(data) }\OperatorTok{*}\StringTok{ }\FloatTok{0.9}\NormalTok{)}
\NormalTok{  train\_set \textless{}{-}}\StringTok{ }\NormalTok{data[}\DecValTok{1}\OperatorTok{:}\NormalTok{train\_index, ]}
\NormalTok{  test\_set \textless{}{-}}\StringTok{ }\NormalTok{data[(train\_index }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(data), ]}

  \CommentTok{\# Define the Gaussian process model}
\NormalTok{  gpr\_model \textless{}{-}}\StringTok{ }\NormalTok{kernlab}\OperatorTok{::}\KeywordTok{gausspr}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(train\_set[, }\KeywordTok{c}\NormalTok{(}\StringTok{"toy"}\NormalTok{, }\StringTok{"temp"}\NormalTok{)]),}
                                \KeywordTok{as.vector}\NormalTok{(train\_set[[class]]),}
                                \DataTypeTok{kernel =}\NormalTok{ kernel, }\DataTypeTok{kpar =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{sigma =}\NormalTok{ sigma))}

  \CommentTok{\# Predict the mean function for plotting}
\NormalTok{  mean\_func \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(gpr\_model, }\KeywordTok{as.vector}\NormalTok{(data}\OperatorTok{$}\NormalTok{toy))}
\NormalTok{  prediction \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
                           \DataTypeTok{toy =}\NormalTok{ data}\OperatorTok{$}\NormalTok{toy,}
                           \DataTypeTok{mean =}\NormalTok{ mean\_func)}

\NormalTok{  data\_with\_pred \textless{}{-}}\StringTok{ }\KeywordTok{left\_join}\NormalTok{(data, prediction, }\DataTypeTok{by =} \StringTok{"toy"}\NormalTok{)}

  \CommentTok{\# Evaluate performance}
\NormalTok{  test\_mean\_func \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(gpr\_model, }\KeywordTok{as.vector}\NormalTok{(test\_set}\OperatorTok{$}\NormalTok{toy))}
\NormalTok{  performance \textless{}{-}}\StringTok{ }\KeywordTok{postResample}\NormalTok{(}\DataTypeTok{pred =}\NormalTok{ test\_mean\_func, }\DataTypeTok{obs =}\NormalTok{ test\_set}\OperatorTok{$}\NormalTok{DE)}

  \CommentTok{\# Include Plots ?}
  \ControlFlowTok{if}\NormalTok{ (plot)\{}
\NormalTok{    pl \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(data\_with\_pred, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ toy)) }\OperatorTok{+}
\StringTok{      }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{get}\NormalTok{(class)), }\DataTypeTok{color =} \StringTok{"\#414141"}\NormalTok{) }\OperatorTok{+}
\StringTok{      }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ mean), }\DataTypeTok{color =}\NormalTok{ class\_colours[class]) }\OperatorTok{+}
\StringTok{      }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"GPR model predictions"}\NormalTok{,}
           \DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Demand"}\NormalTok{)}
\NormalTok{    pl}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    pl \textless{}{-}}\StringTok{ }\OtherTok{NULL}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ gpr\_model,}
\NormalTok{              data \textless{}{-}}\StringTok{ }\NormalTok{data\_with\_pred,}
\NormalTok{              performance,}
              \DataTypeTok{plot =}\NormalTok{ pl))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{results}{%
\section{Results}\label{results}}

\end{document}
