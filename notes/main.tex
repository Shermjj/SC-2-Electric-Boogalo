% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={SC-2 Electric Boogalo},
  pdfauthor={Kieran Morris, Cecina Babich Morrow and Sherman Kjo},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\title{SC-2 Electric Boogalo}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Regression on the Irish datset agregated by class}
\author{Kieran Morris, Cecina Babich Morrow and Sherman Kjo}
\date{}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{3}
\tableofcontents
}
\hypertarget{cleaning-the-data}{%
\section{Cleaning the Data}\label{cleaning-the-data}}

\hypertarget{data-overview}{%
\subsection{Data overview}\label{data-overview}}

We are analyzing a set of Irish household electricity demand available
from the \texttt{electBook} package. We have three datasets:

\begin{itemize}
\tightlist
\item
  \texttt{indCons}: 16799 x 2672 matrix of individual household
  electricity consumption. Each column corresponds to a household and
  each row to a time point. Demand is observed every half hour, so there
  are 48 observations per day per household.
\item
  \texttt{survey}: 2672 row dataframe of household survey data. This
  dataset contains household level data on variables such as social
  class, renting vs.~owning, appliances, etc.
\item
  \texttt{extra}: 16799 row dataframe of time-related variables. This
  dataset contains the date-time of each demand observation, time of
  year, day of week, time of day, whether the day was a holiday, and
  external temperature.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Extract individual dataframes}
\KeywordTok{library}\NormalTok{(electBook)}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{data}\NormalTok{(Irish)}
\NormalTok{indCons \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"indCons"}\NormalTok{]]}
\NormalTok{survey \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"survey"}\NormalTok{]]}
\NormalTok{extra \textless{}{-}}\StringTok{ }\NormalTok{Irish[[}\StringTok{"extra"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\hypertarget{loading-and-structure}{%
\subsection{Loading and Structure}\label{loading-and-structure}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Aggregate total}
\CommentTok{\# Frequency is 30 minutes, so each day has 48 ticks}
\NormalTok{agg \textless{}{-}}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(indCons)}
\end{Highlighting}
\end{Shaded}

\hypertarget{feature-engineering}{%
\subsection{Feature engineering}\label{feature-engineering}}

Based on exploratory data analysis, we created some features from the
dataset to model demand.

\hypertarget{temperature}{%
\subsubsection{Temperature}\label{temperature}}

We can visualize the relationship between temperature and the aggregate
demand over time across all households:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temp\_demand \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{demand =}\NormalTok{ agg) }\OperatorTok{\%\textgreater{}\%}
\StringTok{  }\KeywordTok{bind\_cols}\NormalTok{(Irish[[}\StringTok{"extra"}\NormalTok{]])}

\KeywordTok{ggplot}\NormalTok{(temp\_demand, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ dateTime, }\DataTypeTok{y =}\NormalTok{ demand, }\DataTypeTok{color =}\NormalTok{ temp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom\_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\NormalTok{viridis}\OperatorTok{::}\KeywordTok{scale\_color\_viridis}\NormalTok{(}\DataTypeTok{option =} \StringTok{"magma"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Total Demand"}\NormalTok{, }\DataTypeTok{color =} \StringTok{"Temperature"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{main_files/figure-latex/unnamed-chunk-3-1.pdf}

We can see that during the warmer summer months, demand dips, although
the pattern is messy. We included linear and quadratic terms for
temperature in our models.

\hypertarget{day-of-the-week}{%
\subsubsection{Day of the week}\label{day-of-the-week}}

Since we have the categorical variable day of the week for each date, we
used one-hot encoding to include this information in our models.

\hypertarget{fourier-terms}{%
\subsubsection{Fourier terms}\label{fourier-terms}}

We used Fourier terms to capture the patterns of seasonality in the
data. Fourier terms are a set of sine and cosine functions with
different frequencies that can be used to model periodic patterns. For a
given period \(P\), the Fourier terms are defined as follows:
\[\text{sin}_k(t) = \sin\left(\frac{2\pi kt}{P}\right), \quad \text{cos}_k(t) = \cos\left(\frac{2\pi kt}{P}\right)\]
where \(k\) is the frequency and \(t\) is the time.

We used Fourier terms to model the daily and annual seasonality in the
data.

\hypertarget{social-class}{%
\subsection{Social class}\label{social-class}}

We wanted to investigate demand patterns across different social
classes. The dataset includes 5 social classes, defined by the
occupation of the head of household:

\begin{itemize}
\tightlist
\item
  AB: managerial roles, administrative or professional
\item
  C1: supervisory, clerical, junior managerial
\item
  C2: skilled manual workers
\item
  DE: semi-skilled and unskilled manual workers, state pensioners,
  casual workers
\item
  F: farmers
\end{itemize}

** Insert plot of demand patterns for different classes **

We modeled the average demand for each social class separately.

\hypertarget{simple-regression}{%
\section{Simple Regression}\label{simple-regression}}

\hypertarget{theory}{%
\subsection{Theory}\label{theory}}

\hypertarget{model}{%
\subsection{Model}\label{model}}

\hypertarget{implementation}{%
\subsection{Implementation}\label{implementation}}

\hypertarget{ridge-regression}{%
\section{Ridge Regression}\label{ridge-regression}}

\hypertarget{theory-1}{%
\subsection{Theory}\label{theory-1}}

Ridge regression is a method for penalized regression. Consider the
model \[Y_i^0 = \alpha + \beta x_i^0 + \epsilon_i, \quad  i = 1,..., n\]
where \(\beta \in \mathbb{R}^p\), \(\alpha \in \mathbb{R}\), and for all
\(i, l \in \{1, ..., n\}\), \(\mathbb{E}[\epsilon_i] = 0\) and
\(\mathbb{E}[\epsilon_i \epsilon_l] = \sigma^2 \delta_{il}\) for some
\(\sigma^2 > 0\). Then the ridge regression estimator is defined as the
minimizer of the following objective function:
\[(\hat{\alpha}_\lambda, \hat{\beta}_\lambda) = \mathrm{argmin}_{\alpha \in \mathbb{R}, \beta \in \mathbb{R}^p} \lVert y^0 - \alpha - \boldsymbol{X}^0 \beta \rVert^2_2 + \lambda \lVert \beta \rVert^2_2\]
where \(\lambda > 0\) is a tuning parameter and
\(\lVert \cdot \rVert_2\) denotes the Euclidean norm. Ridge regression
is thus imposing a penalty on the size of \(\beta\), with the strength
of that penalty determined by the choice of \(\lambda\). The
coefficients will be shrunk towards zero, but will not be set to zero
(as opposed to in lasso regression).

\hypertarget{model-1}{%
\subsection{Model}\label{model-1}}

\hypertarget{implementation-1}{%
\subsection{Implementation}\label{implementation-1}}

\hypertarget{gaussian-process-regression}{%
\section{Gaussian Process
Regression}\label{gaussian-process-regression}}

\hypertarget{theory-2}{%
\subsection{Theory}\label{theory-2}}

A gaussian process is a collection of random variables, which have a
joint Gaussian distribution. A Gaussian process is completely specified
by its mean function and covariance function. We build the following
model:

Let \(y_i = f(x_i) + \varepsilon_i\), where
\(f(x) \sim \text{GP}(0, k(x, x'))\) and
\(\varepsilon_i \sim N(0, \sigma^2)\). Then we can find the posterior
distribution of \(f(x_*)\) given \(y\) as:

\[
f(x_*) | y \sim N(\mu(x_*), \sigma^2(x_*))
\]

where \(\mu(x_*) = k(x_*, x)^T(K + \sigma^2I)^{-1}y\) and
\(\sigma^2(x_*) = k(x_*, x_*) - k(x_*, x)^T(K + \sigma^2I)^{-1}k(x_*, x)\).
In pratice, to find the posterior distribution, we maximise the marginal
log-likelihood.

\hypertarget{model-2}{%
\subsection{Model}\label{model-2}}

\hypertarget{implementation-2}{%
\subsection{Implementation}\label{implementation-2}}

For the gaussian process regression, we will use the
\texttt{kernlab::gausspr} function, which can perform multivariate
gaussian process regression, allowing us to add our additional features
as covariates. By convention we will use the rbf kernel:

\[
k(x, x') = \exp\left(-\frac{\lVert x - x' \rVert^2}{2l}\right)
\]

where \(l\) is another hyperparameter to be tuned. Below is our code
which fits the gaussian process regression model to given data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gaussian\_process\_reg \textless{}{-}}\StringTok{ }\ControlFlowTok{function}\NormalTok{(data,}
                                 \DataTypeTok{class =} \StringTok{"DE"}\NormalTok{,}
                                 \DataTypeTok{kernel =} \StringTok{"rbfdot"}\NormalTok{,}
                                 \DataTypeTok{plot =} \OtherTok{FALSE}\NormalTok{,}
                                 \DataTypeTok{sigma =} \DecValTok{100}\NormalTok{) \{}

  \CommentTok{\#Training and test set, first 90\% of data is training, last 10\% is test}
\NormalTok{  train\_index \textless{}{-}}\StringTok{ }\KeywordTok{round}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(data) }\OperatorTok{*}\StringTok{ }\FloatTok{0.9}\NormalTok{)}
\NormalTok{  train\_set \textless{}{-}}\StringTok{ }\NormalTok{data[}\DecValTok{1}\OperatorTok{:}\NormalTok{train\_index, ]}
\NormalTok{  test\_set \textless{}{-}}\StringTok{ }\NormalTok{data[(train\_index }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{)}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(data), ]}

  \CommentTok{\# Define the Gaussian process model}
\NormalTok{  gpr\_model \textless{}{-}}\StringTok{ }\NormalTok{kernlab}\OperatorTok{::}\KeywordTok{gausspr}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(train\_set[, }\KeywordTok{c}\NormalTok{(}\StringTok{"toy"}\NormalTok{, }\StringTok{"temp"}\NormalTok{)]),}
                                \KeywordTok{as.vector}\NormalTok{(train\_set[[class]]),}
                                \DataTypeTok{kernel =}\NormalTok{ kernel, }\DataTypeTok{kpar =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{sigma =}\NormalTok{ sigma))}

  \CommentTok{\# Predict the mean function for plotting}
\NormalTok{  mean\_func \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(gpr\_model, }\KeywordTok{as.vector}\NormalTok{(data}\OperatorTok{$}\NormalTok{toy))}
\NormalTok{  prediction \textless{}{-}}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}
                           \DataTypeTok{toy =}\NormalTok{ data}\OperatorTok{$}\NormalTok{toy,}
                           \DataTypeTok{mean =}\NormalTok{ mean\_func)}

\NormalTok{  data\_with\_pred \textless{}{-}}\StringTok{ }\KeywordTok{left\_join}\NormalTok{(data, prediction, }\DataTypeTok{by =} \StringTok{"toy"}\NormalTok{)}

  \CommentTok{\# Evaluate performance}
\NormalTok{  test\_mean\_func \textless{}{-}}\StringTok{ }\KeywordTok{predict}\NormalTok{(gpr\_model, }\KeywordTok{as.vector}\NormalTok{(test\_set}\OperatorTok{$}\NormalTok{toy))}
\NormalTok{  performance \textless{}{-}}\StringTok{ }\KeywordTok{postResample}\NormalTok{(}\DataTypeTok{pred =}\NormalTok{ test\_mean\_func, }\DataTypeTok{obs =}\NormalTok{ test\_set}\OperatorTok{$}\NormalTok{DE)}

  \CommentTok{\# Include Plots ?}
  \ControlFlowTok{if}\NormalTok{ (plot)\{}
\NormalTok{    pl \textless{}{-}}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(data\_with\_pred, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ toy)) }\OperatorTok{+}
\StringTok{      }\KeywordTok{geom\_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{get}\NormalTok{(class)), }\DataTypeTok{color =} \StringTok{"\#414141"}\NormalTok{) }\OperatorTok{+}
\StringTok{      }\KeywordTok{geom\_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ mean), }\DataTypeTok{color =}\NormalTok{ class\_colours[class]) }\OperatorTok{+}
\StringTok{      }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{title =} \StringTok{"GPR model predictions"}\NormalTok{,}
           \DataTypeTok{x =} \StringTok{"Date"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Demand"}\NormalTok{)}
\NormalTok{    pl}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    pl \textless{}{-}}\StringTok{ }\OtherTok{NULL}
\NormalTok{  \}}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{model =}\NormalTok{ gpr\_model,}
\NormalTok{              data \textless{}{-}}\StringTok{ }\NormalTok{data\_with\_pred,}
\NormalTok{              performance,}
              \DataTypeTok{plot =}\NormalTok{ pl))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Since we are working as bayesians to find the ideal hyperparameters
\(l\) and \(\sigma\), we will minimise the negative log likelihood of
the model. On one hand this skirts the issues of cross validation, but
on the other hand we are left with a non convex optimisation problem. To
get around this issue we outsoucre to C++, making use of the C++
optimising library optim. Then parallizing with RcppArmadillo to
parallelise the optimisation over a two dimensional grid of intiial
choices. Below is the \texttt{RcppArmadillo} code we used to optimise
the hyperparameters:

\begin{Shaded}
\begin{Highlighting}[]
\PreprocessorTok{\#include }\ImportTok{\textless{}RcppArmadillo.h\textgreater{}}
\PreprocessorTok{\#include }\ImportTok{\textless{}optim.hpp\textgreater{}}

\CommentTok{// [[Rcpp::depends(RcppArmadillo)]]}

\CommentTok{// Define the RBF kernel}
\NormalTok{arma::mat rbf\_kernel(}\AttributeTok{const}\NormalTok{ arma::mat\& X, }\DataTypeTok{double}\NormalTok{ l, }\DataTypeTok{double}\NormalTok{ sigma) \{}
\NormalTok{    arma::mat K = arma::zeros(X.n\_rows, X.n\_rows);}
    \ControlFlowTok{for}\NormalTok{ (}\DataTypeTok{unsigned}\NormalTok{ i = }\DecValTok{0}\NormalTok{; i \textless{} X.n\_rows; ++i) \{}
        \ControlFlowTok{for}\NormalTok{ (}\DataTypeTok{unsigned}\NormalTok{ j = }\DecValTok{0}\NormalTok{; j \textless{} X.n\_rows; ++j) \{}
            \DataTypeTok{double}\NormalTok{ dist = arma::norm(X.row(i) {-} X.row(j), }\DecValTok{2}\NormalTok{);}
\NormalTok{            K(i, j) = }\BuiltInTok{std::}\NormalTok{pow(sigma, }\DecValTok{2}\NormalTok{) * }\BuiltInTok{std::}\NormalTok{exp({-}}\BuiltInTok{std::}\NormalTok{pow(dist, }\DecValTok{2}\NormalTok{) / (}\DecValTok{2}\NormalTok{ * }\BuiltInTok{std::}\NormalTok{pow(l, }\DecValTok{2}\NormalTok{)));}
\NormalTok{        \}}
\NormalTok{    \}}
    \ControlFlowTok{return}\NormalTok{ K;}
\NormalTok{\}}

\CommentTok{// Define the negative log marginal likelihood}
\DataTypeTok{double}\NormalTok{ neg\_log\_marginal\_likelihood(}\AttributeTok{const}\NormalTok{ arma::vec\& theta, arma::vec* grad\_out, }\DataTypeTok{void}\NormalTok{* opt\_data) \{}
    \CommentTok{// Extract data and parameters}
\NormalTok{    arma::mat X = *}\KeywordTok{static\_cast}\NormalTok{\textless{}arma::mat*\textgreater{}(opt\_data);}
\NormalTok{    arma::vec y = *}\KeywordTok{static\_cast}\NormalTok{\textless{}arma::vec*\textgreater{}(opt\_data);}
    \DataTypeTok{double}\NormalTok{ l = theta(}\DecValTok{0}\NormalTok{);}
    \DataTypeTok{double}\NormalTok{ sigma = theta(}\DecValTok{1}\NormalTok{);}

    \CommentTok{// Calculate the kernel matrix}
\NormalTok{    arma::mat K = rbf\_kernel(X, l, sigma);}

    \CommentTok{// Calculate the log marginal likelihood}
    
    \DataTypeTok{double}\NormalTok{ log\_likelihood = {-}}\FloatTok{0.5}\NormalTok{ * arma::as\_scalar(y.t() * arma::solve(K, y)) {-} }\FloatTok{0.5}\NormalTok{ * arma::log\_det(K + l ) {-} }\FloatTok{0.5}\NormalTok{ * X.n\_rows * }\BuiltInTok{std::}\NormalTok{log(}\DecValTok{2}\NormalTok{ * M\_PI);}

    \CommentTok{// Return the negative log marginal likelihood}
    \ControlFlowTok{return}\NormalTok{ {-}log\_likelihood;}
\NormalTok{\}}

\CommentTok{// [[Rcpp::export]]}
\NormalTok{arma::vec optimise\_gaussian\_process(arma::mat X, arma::vec y) \{}
    \CommentTok{// Initial guess for the parameters}
\NormalTok{    arma::vec theta = arma::ones(}\DecValTok{2}\NormalTok{);}

    \CommentTok{// Optimise the negative log marginal likelihood}
    \DataTypeTok{bool}\NormalTok{ success = optim::de(theta, neg\_log\_marginal\_likelihood, \&X);}

    \CommentTok{// Return the optimised parameters}
    \ControlFlowTok{return}\NormalTok{ theta;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{results}{%
\section{Results}\label{results}}

\end{document}
